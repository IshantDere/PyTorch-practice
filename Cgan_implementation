import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Hyperparameters

batch_size = 64
z_dim = 100
num_classes = 10
lr = 2e-4
epochs = 3
device = "cuda" if torch.cuda.is_available() else "cpu"


transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])
train_dataset = datasets.MNIST(root="./data", train=True, transform=transform, download=True)
loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)


class Generator(nn.Module):
    def __init__(self, z_dim, num_classes):
        super().__init__()
        self.label_emb = nn.Embedding(num_classes, num_classes)
        self.model = nn.Sequential(
            nn.Linear(z_dim + num_classes, 256),
            nn.ReLU(True),
            nn.Linear(256, 512),
            nn.ReLU(True),
            nn.Linear(512, 28*28),
            nn.Tanh()
        )
    def forward(self, noise, labels):
        c = self.label_emb(labels)
        x = torch.cat([noise, c], 1)
        return self.model(x).view(-1, 1, 28, 28)


class Discriminator(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.label_emb = nn.Embedding(num_classes, num_classes)
        self.model = nn.Sequential(
            nn.Linear(28*28 + num_classes, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )
    def forward(self, imgs, labels):
        c = self.label_emb(labels)
        x = torch.cat([imgs.view(imgs.size(0), -1), c], 1)
        return self.model(x)


gen = Generator(z_dim, num_classes).to(device)
disc = Discriminator(num_classes).to(device)
opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))
opt_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))
criterion = nn.BCELoss()

for epoch in range(epochs):
    for real, labels in loader:
        real, labels = real.to(device), labels.to(device)
        batch_size = real.size(0)

        ### Train Discriminator ###
        noise = torch.randn(batch_size, z_dim).to(device)
        fake = gen(noise, labels)

        disc_real = disc(real, labels)
        disc_fake = disc(fake.detach(), labels)
        loss_disc = criterion(disc_real, torch.ones_like(disc_real)) + \
                    criterion(disc_fake, torch.zeros_like(disc_fake))
        opt_disc.zero_grad()
        loss_disc.backward()
        opt_disc.step()

        ### Train Generator ###
        output = disc(fake, labels)
        loss_gen = criterion(output, torch.ones_like(output))
        opt_gen.zero_grad()
        loss_gen.backward()
        opt_gen.step()

    print(f"Epoch [{epoch+1}/{epochs}] Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}")
